{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image, ImageEnhance, ImageFilter\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torchvision.models import resnet50, ResNet50_Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "csv_file = 'train.csv'  \n",
    "img_dir = 'train'  \n",
    "augmented_csv_file = 'augmented_train.csv'  # CSV file to save augmented metadata\n",
    "features_csv_file = 'extracted_features.csv'  # CSV file to save extracted features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load csv\n",
    "train_df = pd.read_csv(csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Initial DataFrame:\")\n",
    "print(train_df.head())\n",
    "print(\"\\nDataFrame Info:\")\n",
    "print(train_df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for any missing values\n",
    "if train_df.isnull().any().any():\n",
    "    print(\"Missing values found:\")\n",
    "    print(train_df.isnull().sum())\n",
    "    \n",
    "else:\n",
    "    print(\"No missing values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for duplicates\n",
    "duplicates = train_df.duplicated().sum()\n",
    "if duplicates > 0:\n",
    "    print(f\"Duplicates found: {duplicates}\")\n",
    "    train_df.drop_duplicates(inplace=True)\n",
    "    \n",
    "else:\n",
    "    print(\"No duplicates found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting pawpularity to float\n",
    "train_df['Pawpularity'] = train_df['Pawpularity'].astype(float)\n",
    "\n",
    "# Normalize Pawpularity to a range between 0 and 1\n",
    "train_df['Pawpularity'] = train_df['Pawpularity'] / 100.0  # [0, 1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Augmentation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_image(img, size=(224, 224)):\n",
    "    return img.resize(size)\n",
    "\n",
    "def normalize_image(img):\n",
    "    img_array = np.array(img) / 255.0\n",
    "    return Image.fromarray((img_array * 255).astype(np.uint8))  # Convert back to image if needed\n",
    "\n",
    "def random_flip(img):\n",
    "    if random.random() > 0.3:\n",
    "        return img.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "    return img\n",
    "\n",
    "def random_vertical_flip(img):\n",
    "    if random.random() > 0.3:\n",
    "        return img.transpose(Image.FLIP_TOP_BOTTOM)\n",
    "    return img\n",
    "\n",
    "def random_rotation(img, max_angle=10): \n",
    "    angle = random.uniform(-max_angle, max_angle)\n",
    "    return img.rotate(angle)\n",
    "\n",
    "def color_jitter(img, brightness=0.1, contrast=0.1, saturation=0.1):  \n",
    "    img = ImageEnhance.Brightness(img).enhance(1 + random.uniform(-brightness, brightness))\n",
    "    img = ImageEnhance.Contrast(img).enhance(1 + random.uniform(-contrast, contrast))\n",
    "    img = ImageEnhance.Color(img).enhance(1 + random.uniform(-saturation, saturation))\n",
    "    return img\n",
    "\n",
    "def gaussian_blur(img, radius=0.5): \n",
    "    return img.filter(ImageFilter.GaussianBlur(radius))\n",
    "\n",
    "def random_grayscale(img, p=0.1): \n",
    "    if random.random() < p:\n",
    "        return img.convert(\"L\").convert(\"RGB\")  # Convert to grayscale and back to RGB\n",
    "    return img\n",
    "\n",
    "def random_noise(img, noise_factor=0.01):  \n",
    "    img_array = np.array(img)\n",
    "    noise = np.random.normal(0, noise_factor * 255, img_array.shape).astype(np.uint8)\n",
    "    noisy_img_array = np.clip(img_array + noise, 0, 255)\n",
    "    return Image.fromarray(noisy_img_array.astype(np.uint8))\n",
    "\n",
    "def random_perspective(img, distortion=0.1): \n",
    "    width, height = img.size\n",
    "    x_shift = distortion * width\n",
    "    y_shift = distortion * height\n",
    "\n",
    "    coeffs = [\n",
    "        x_shift, y_shift,\n",
    "        width - x_shift, y_shift,\n",
    "        width - x_shift, height - y_shift,\n",
    "        x_shift, height - y_shift,\n",
    "    ]\n",
    "    return img.transform(img.size, Image.QUAD, coeffs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating 5 augmented images for each original image, with combinations of 3 or more possible augmentations\n",
    "def augment_image(img, num_augmentations=5):\n",
    "    augmentations = [\n",
    "        random_flip,\n",
    "        random_vertical_flip,\n",
    "        random_rotation,\n",
    "        color_jitter,\n",
    "        gaussian_blur,\n",
    "        random_grayscale,\n",
    "        random_noise,\n",
    "        random_perspective\n",
    "    ]\n",
    "    \n",
    "    augmented_images = []\n",
    "    for _ in range(num_augmentations):\n",
    "        aug_img = img\n",
    "        for aug in random.sample(augmentations, k=random.randint(3, len(augmentations))):\n",
    "            aug_img = aug(aug_img)\n",
    "        aug_img = transforms.Resize((224, 224))(aug_img)\n",
    "        aug_img = transforms.ToTensor()(aug_img)  # Convert to tensor for deep learning models\n",
    "        augmented_images.append(aug_img)\n",
    "    return augmented_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up GPU for feature extraction\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a pre-trained model for feature extraction\n",
    "model = resnet50(weights=ResNet50_Weights.DEFAULT).to(device)\n",
    "model.eval()  # Set to evaluation mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define image transformations for feature extraction\n",
    "feature_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(img):\n",
    "    img_tensor = feature_transform(img)  # Apply feature extraction transformations\n",
    "    with torch.no_grad():\n",
    "        img_tensor = img_tensor.to(device)\n",
    "        features = model(img_tensor.unsqueeze(0))\n",
    "    return features.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List to hold rows for the new CSV file\n",
    "augmented_data = []\n",
    "features_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, row in tqdm(train_df.iterrows(), total=len(train_df)):\n",
    "    img_path = os.path.join(img_dir, row['Image'])  # Adjust column name if needed\n",
    "    img = Image.open(img_path).convert(\"RGB\")  # Open and convert image to RGB\n",
    "    \n",
    "    # Generate 5 augmented images\n",
    "    augmented_images = augment_image(img, num_augmentations=5)\n",
    "    \n",
    "    for i, aug_img in enumerate(augmented_images):\n",
    "        augmented_data.append({'Image': f\"{row['Image']}_aug_{i+1}\", 'Pawpularity': row['Pawpularity']})\n",
    "        \n",
    "        # Extract features for each augmented image\n",
    "        features = extract_features(aug_img)\n",
    "        features_list.append((features.flatten(), row['Pawpularity']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving augmented metadata to csv\n",
    "augmented_df = pd.DataFrame(augmented_data)\n",
    "augmented_df.to_csv(augmented_csv_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving features to CSV\n",
    "features_df = pd.DataFrame(features_list, columns=['Features', 'Pawpularity'])\n",
    "features_df['Features'] = features_df['Features'].apply(lambda x: ','.join(map(str, x)))  # Flatten for CSV\n",
    "features_df.to_csv(features_csv_file, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
