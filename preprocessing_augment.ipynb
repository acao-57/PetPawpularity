{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image, ImageEnhance, ImageFilter\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torchvision.models import resnet50, ResNet50_Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "csv_file = 'train.csv'  \n",
    "img_dir = 'train'  \n",
    "output_img_dir = 'augmented_images'  # Folder to save augmented images\n",
    "output_csv_file = 'augmented_train.csv'  # CSV file to save updated data\n",
    "features_csv_file = 'extracted_features.csv'  # CSV file to save extracted features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load csv\n",
    "train_df = pd.read_csv(csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial DataFrame:\n",
      "                                 Id  Subject Focus  Eyes  Face  Near  Action  \\\n",
      "0  0007de18844b0dbbb5e1f607da0606e0              0     1     1     1       0   \n",
      "1  0009c66b9439883ba2750fb825e1d7db              0     1     1     0       0   \n",
      "2  0013fd999caf9a3efe1352ca1b0d937e              0     1     1     1       0   \n",
      "3  0018df346ac9c1d8413cfcc888ca8246              0     1     1     1       0   \n",
      "4  001dc955e10590d3ca4673f034feeef2              0     0     0     1       0   \n",
      "\n",
      "   Accessory  Group  Collage  Human  Occlusion  Info  Blur  Pawpularity  \n",
      "0          0      1        0      0          0     0     0           63  \n",
      "1          0      0        0      0          0     0     0           42  \n",
      "2          0      0        0      1          1     0     0           28  \n",
      "3          0      0        0      0          0     0     0           15  \n",
      "4          0      1        0      0          0     0     0           72  \n",
      "\n",
      "DataFrame Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9912 entries, 0 to 9911\n",
      "Data columns (total 14 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   Id             9912 non-null   object\n",
      " 1   Subject Focus  9912 non-null   int64 \n",
      " 2   Eyes           9912 non-null   int64 \n",
      " 3   Face           9912 non-null   int64 \n",
      " 4   Near           9912 non-null   int64 \n",
      " 5   Action         9912 non-null   int64 \n",
      " 6   Accessory      9912 non-null   int64 \n",
      " 7   Group          9912 non-null   int64 \n",
      " 8   Collage        9912 non-null   int64 \n",
      " 9   Human          9912 non-null   int64 \n",
      " 10  Occlusion      9912 non-null   int64 \n",
      " 11  Info           9912 non-null   int64 \n",
      " 12  Blur           9912 non-null   int64 \n",
      " 13  Pawpularity    9912 non-null   int64 \n",
      "dtypes: int64(13), object(1)\n",
      "memory usage: 1.1+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(\"Initial DataFrame:\")\n",
    "print(train_df.head())\n",
    "print(\"\\nDataFrame Info:\")\n",
    "print(train_df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No missing values\n"
     ]
    }
   ],
   "source": [
    "# Checking for any missing values\n",
    "if train_df.isnull().any().any():\n",
    "    print(\"Missing values found:\")\n",
    "    print(train_df.isnull().sum())\n",
    "    \n",
    "else:\n",
    "    print(\"No missing values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No duplicates found\n"
     ]
    }
   ],
   "source": [
    "# Checking for duplicates\n",
    "duplicates = train_df.duplicated().sum()\n",
    "if duplicates > 0:\n",
    "    print(f\"Duplicates found: {duplicates}\")\n",
    "    train_df.drop_duplicates(inplace=True)\n",
    "    \n",
    "else:\n",
    "    print(\"No duplicates found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting pawpularity to float\n",
    "train_df['Pawpularity'] = train_df['Pawpularity'].astype(float)\n",
    "\n",
    "# Normalize Pawpularity to a range between 0 and 1\n",
    "train_df['Pawpularity'] = train_df['Pawpularity'] / 100.0  # [0, 1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Augmentation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_image(img, size=(224, 224)):\n",
    "    return img.resize(size)\n",
    "\n",
    "def normalize_image(img):\n",
    "    img_array = np.array(img) / 255.0\n",
    "    return Image.fromarray((img_array * 255).astype(np.uint8))  # Convert back to image if needed\n",
    "\n",
    "def random_flip(img):\n",
    "    if random.random() > 0.5:\n",
    "        return img.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "    return img\n",
    "\n",
    "def random_vertical_flip(img):\n",
    "    if random.random() > 0.5:\n",
    "        return img.transpose(Image.FLIP_TOP_BOTTOM)\n",
    "    return img\n",
    "\n",
    "def random_rotation(img, max_angle=10): \n",
    "    angle = random.uniform(-max_angle, max_angle)\n",
    "    return img.rotate(angle)\n",
    "\n",
    "def color_jitter(img, brightness=0.1, contrast=0.1, saturation=0.1):  \n",
    "    img = ImageEnhance.Brightness(img).enhance(1 + random.uniform(-brightness, brightness))\n",
    "    img = ImageEnhance.Contrast(img).enhance(1 + random.uniform(-contrast, contrast))\n",
    "    img = ImageEnhance.Color(img).enhance(1 + random.uniform(-saturation, saturation))\n",
    "    return img\n",
    "\n",
    "def gaussian_blur(img, radius=0.5): \n",
    "    return img.filter(ImageFilter.GaussianBlur(radius))\n",
    "\n",
    "def random_grayscale(img, p=0.1): \n",
    "    if random.random() < p:\n",
    "        return img.convert(\"L\").convert(\"RGB\")  # Convert to grayscale and back to RGB\n",
    "    return img\n",
    "\n",
    "def random_noise(img, noise_factor=0.01):  \n",
    "    img_array = np.array(img)\n",
    "    noise = np.random.normal(0, noise_factor * 255, img_array.shape).astype(np.uint8)\n",
    "    noisy_img_array = np.clip(img_array + noise, 0, 255)\n",
    "    return Image.fromarray(noisy_img_array.astype(np.uint8))\n",
    "\n",
    "def random_perspective(img, distortion=0.1): \n",
    "    width, height = img.size\n",
    "    x_shift = distortion * width\n",
    "    y_shift = distortion * height\n",
    "\n",
    "    coeffs = [\n",
    "        x_shift, y_shift,\n",
    "        width - x_shift, y_shift,\n",
    "        width - x_shift, height - y_shift,\n",
    "        x_shift, height - y_shift,\n",
    "    ]\n",
    "    return img.transform(img.size, Image.QUAD, coeffs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to C:\\Users\\tongs/.cache\\torch\\hub\\checkpoints\\resnet50-11ad3fa6.pth\n",
      "100%|██████████| 97.8M/97.8M [00:08<00:00, 11.8MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load a pre-trained model for feature extraction\n",
    "model = resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "model.eval()  # Set to evaluation mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define image transformations for feature extraction\n",
    "feature_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List to hold rows for the new CSV file\n",
    "augmented_rows = []\n",
    "extracted_features = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(img_path):\n",
    "    img = Image.open(img_path).convert('RGB')  # Open image\n",
    "    img_tensor = feature_transform(img).unsqueeze(0)  # Transform and add batch dimension\n",
    "    with torch.no_grad():  # Disable gradient calculation\n",
    "        features = model(img_tensor).flatten().numpy()  # Extract features and flatten\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▋        | 1619/9912 [08:55<45:41,  3.03it/s] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 80\u001b[0m\n\u001b[0;32m     77\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     78\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError processing image \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimg_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 80\u001b[0m \u001b[43maugment_images\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_img_dir\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[13], line 54\u001b[0m, in \u001b[0;36maugment_images\u001b[1;34m(train_df, img_dir, output_img_dir)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;66;03m# Save the augmented image with a unique filename\u001b[39;00m\n\u001b[0;32m     53\u001b[0m augmented_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moriginal_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_aug\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 54\u001b[0m \u001b[43maugmented_img\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_img_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43maugmented_id\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.jpg\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# Extract features from the augmented image\u001b[39;00m\n\u001b[0;32m     57\u001b[0m aug_features \u001b[38;5;241m=\u001b[39m extract_features(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(output_img_dir, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maugmented_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "File \u001b[1;32mc:\\ML-sc4000\\myenv\\Lib\\site-packages\\PIL\\Image.py:2600\u001b[0m, in \u001b[0;36mImage.save\u001b[1;34m(self, fp, format, **params)\u001b[0m\n\u001b[0;32m   2598\u001b[0m         fp \u001b[38;5;241m=\u001b[39m builtins\u001b[38;5;241m.\u001b[39mopen(filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr+b\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   2599\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2600\u001b[0m         fp \u001b[38;5;241m=\u001b[39m \u001b[43mbuiltins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mw+b\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2601\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2602\u001b[0m     fp \u001b[38;5;241m=\u001b[39m cast(IO[\u001b[38;5;28mbytes\u001b[39m], fp)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def augment_images(train_df, img_dir, output_img_dir):\n",
    "    if not os.path.exists(output_img_dir):\n",
    "        os.makedirs(output_img_dir)\n",
    "\n",
    "    for idx, row in tqdm(train_df.iterrows(), total=len(train_df)):\n",
    "        original_id = row['Id']\n",
    "        pawpularity_score = row['Pawpularity']\n",
    "        # Include additional columns to copy over\n",
    "        subject_focus = row['Subject Focus']\n",
    "        eyes = row['Eyes']\n",
    "        face = row['Face']\n",
    "        near = row['Near']\n",
    "        action = row['Action']\n",
    "        accessory = row['Accessory']\n",
    "        group = row['Group']\n",
    "        collage = row['Collage']\n",
    "        human = row['Human']\n",
    "        occlusion = row['Occlusion']\n",
    "        info = row['Info']\n",
    "        blur = row['Blur']\n",
    "\n",
    "        img_path = os.path.join(img_dir, f\"{original_id}.jpg\")\n",
    "\n",
    "        # Append the original row (for the unaugmented image)\n",
    "        augmented_rows.append(row.to_dict())\n",
    "\n",
    "        # Open and transform the image\n",
    "        try:\n",
    "            with Image.open(img_path) as img:\n",
    "                # Preprocessing: Resize and normalize\n",
    "                original_resized = resize_image(img)\n",
    "                original_resized = normalize_image(original_resized)\n",
    "                original_resized.save(os.path.join(output_img_dir, f\"{original_id}.jpg\"))\n",
    "\n",
    "                # Extract features from the original image\n",
    "                features = extract_features(img_path)\n",
    "                extracted_features.append(features)  # Store features\n",
    "\n",
    "                # Augment and save\n",
    "                for i in range(5):  # Number of augmented versions per image\n",
    "                    augmented_img = resize_image(img)\n",
    "                    augmented_img = normalize_image(augmented_img)\n",
    "                    augmented_img = random_flip(augmented_img)\n",
    "                    augmented_img = random_vertical_flip(augmented_img)\n",
    "                    augmented_img = random_rotation(augmented_img)\n",
    "                    augmented_img = color_jitter(augmented_img)\n",
    "                    augmented_img = gaussian_blur(augmented_img)\n",
    "                    augmented_img = random_grayscale(augmented_img)\n",
    "                    augmented_img = random_noise(augmented_img)\n",
    "                    augmented_img = random_perspective(augmented_img)\n",
    "\n",
    "                    # Save the augmented image with a unique filename\n",
    "                    augmented_id = f\"{original_id}_aug{i}\"\n",
    "                    augmented_img.save(os.path.join(output_img_dir, f\"{augmented_id}.jpg\"))\n",
    "\n",
    "                    # Extract features from the augmented image\n",
    "                    aug_features = extract_features(os.path.join(output_img_dir, f\"{augmented_id}.jpg\"))\n",
    "                    extracted_features.append(aug_features)  # Store features\n",
    "\n",
    "                    # Add a row for the augmented image in the new CSV data\n",
    "                    augmented_rows.append({\n",
    "                        'Id': augmented_id,\n",
    "                        'Pawpularity': pawpularity_score,\n",
    "                        'Subject Focus': subject_focus,\n",
    "                        'Eyes': eyes,\n",
    "                        'Face': face,\n",
    "                        'Near': near,\n",
    "                        'Action': action,\n",
    "                        'Accessory': accessory,\n",
    "                        'Group': group,\n",
    "                        'Collage': collage,\n",
    "                        'Human': human,\n",
    "                        'Occlusion': occlusion,\n",
    "                        'Info': info,\n",
    "                        'Blur': blur,\n",
    "                    })\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing image {img_path}: {e}\")\n",
    "            \n",
    "augment_images(train_df, img_dir, output_img_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting extracted features to df\n",
    "features_df = pd.DataFrame(extracted_features, columns=[f'Feature_{i}' for i in range(len(extracted_features[0]))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine augmented data with preprocessed CSV\n",
    "if augmented_rows:\n",
    "    # Create a DataFrame from the augmented rows\n",
    "    augmented_df = pd.DataFrame(augmented_rows)\n",
    "    \n",
    "    # Load existing preprocessed CSV\n",
    "    if os.path.exists(output_csv_file):\n",
    "        existing_df = pd.read_csv(output_csv_file)\n",
    "        \n",
    "        # Combine the two DataFrames\n",
    "        combined_df = pd.concat([existing_df, augmented_df], ignore_index=True)\n",
    "    else:\n",
    "        # If the CSV does not exist, use only the augmented DataFrame\n",
    "        combined_df = augmented_df\n",
    "\n",
    "    # Save the combined data back to the preprocessed CSV file\n",
    "    combined_df.to_csv(output_csv_file, index=False)\n",
    "    features_df.to_csv(features_csv_file, index=False)  # Save extracted features\n",
    "    print(\"Combined data and extracted features saved to:\", output_csv_file)\n",
    "else:\n",
    "    print(\"No augmented data to combine.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
